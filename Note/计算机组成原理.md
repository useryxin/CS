#### 线程与进程的区别		

​		线程的栈被自动分配到进程的内存空间中 进程和线程都是由操作系统所体会的程序运行的基本单元，系统利用该基本单元实现系统对应用的并发性。

​		进程和线程的区别在于： 简而言之,一个程序至少有一个进程,一个进程至少有一个线程.  线程的划分尺度小于进程，使得多线程程序的并发性高。 另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。

​		线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。 从逻辑角度来看，多线程的l意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。 

​		进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位.  线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源. 一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行. 

​		堆：是大家共有的空间，分全局堆和局部堆。

​		全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。堆在操作系统对进程初始化的时候分配，运行过程中也可以向系统要额外的堆，但是记得用完了要还给操作系统，要不然就是内存泄漏。

​		栈：是个线程独有的，保存其运行状态和局部自动变量的。

​		栈在线程开始的时候初始化，每个线程的栈互相独立，因此，栈是thread safe的。每个C++对象的数据成员也存在在栈中，每个函数都有自己的栈，栈被用来在函数之间传递参数。操作系统在切换线程的时候会自动的切换栈，就是切换　SS/ESP寄存器。栈空间不需要在高级语言里面显式的分配和释放。



​		线程（Thread）和进程（Process）是操作系统中用于执行程序的两个关键概念，它们在多任务处理中扮演不同的角色。以下是线程和进程之间的主要区别：

1. **基本定义**：
   - 进程是一个独立的执行单元，具有自己的独立内存空间和资源。每个进程都有自己的地址空间，代码段，数据段，和堆栈等。
   - 线程是进程内的执行单元，多个线程共享同一进程的内存空间和资源。线程属于同一进程，它们共享进程的上下文和数据。

2. **资源消耗**：
   - 进程之间的切换通常需要更多的资源，因为它涉及到切换不同的内存空间和上下文。
   - 线程之间的切换通常更轻量，因为它们共享相同的内存空间和资源，切换的开销较小。

3. **通信和同步**：
   - 进程之间的通信通常需要使用额外的机制，如管道、消息队列、共享内存等，因为它们拥有不同的内存空间。
   - 线程之间的通信和同步相对容易，可以直接访问相同的内存，也可以使用线程同步机制如互斥锁、信号量等来协调线程的执行。

4. **独立性**：
   - 进程是相对独立的执行单元，一个进程的崩溃通常不会影响其他进程。
   - 线程之间更加紧密，一个线程的错误可能会导致整个进程的崩溃。

5. **创建和销毁**：
   - 创建和销毁进程通常比线程更加耗时和复杂，因为需要分配和释放独立的内存空间。
   - 创建和销毁线程通常更快速和简单，因为它们共享相同的内存空间。

6. **并行性**：
   - 进程之间可以并行执行，因为它们具有独立的内存空间，可以在多核处理器上同时运行。
   - 线程在单个进程内并行执行，因此受到进程的限制，只能在单个核心上并行执行，除非使用多线程编程库来实现真正的并行性。

7. **安全性**：
   - 由于线程共享进程的内存空间，线程之间访问共享数据时需要谨慎处理同步和互斥，以避免竞态条件和数据损坏。
   - 进程之间的数据隔离较好，一个进程的错误不太可能影响其他进程。

总结来说，进程和线程都是多任务处理的关键元素，但它们在资源消耗、通信和同步、独立性、创建销毁等方面存在重要的区别。选择使用进程还是线程取决于应用程序的需求和性能要求。通常情况下，线程更适用于需要轻量级并发和共享内存的情况，而进程更适用于隔离和资源分离的情况。



###  堆和栈的区别

##### 一、预备知识

程序的内存分配  一个由c/C++编译的程序占用的内存分为以下几个部分：  

​		栈区（stack）— 由编译器自动分配释放，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。  

​		堆区（heap） — 一般由程序员分配释放，若程序员不释放，程序结束时可能由OS回收。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表。  

​		全局区（静态区）（static）—，全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。 - 程序结束后由系统释放。 

​		文字常量区   —常量字符串就是放在这里的。程序结束后由系统释放。 

​		程序代码区—存放函数体的二进制代码。 

#####  二、例子程序

```c
int a = 0;\\ 全局初始化区  
char *p1; \\全局未初始化区  
main(){
    int b; \\栈  
    char s[] = "abc"; \\栈  
    char *p2; \\栈  
    char *p3 = "123456"; \\123456\0在常量区，p3在栈上  
    static int c =0;\\全局（静态）初始化区  
    p1 = (char *)malloc(10);
    p2 = (char *)malloc(20);  //分配得来得10和20字节的区域就在堆区。  
    strcpy(p1, "123456"); //123456\0放在常量区，编译器可能会将它与p3所指向的"123456"优化成一个地方。  }
```

#####  三、堆和栈的理论知识  

###### 		2.1申请方式  

​			stack:  由系统自动分配。

​			例如，声明在函数中一个局部变量 int b; 系统自动在栈中为b开辟空间  heap:  需要程序员自己申请，并指明大小，在c中`malloc`函		数  如`p1 = (char *)malloc(10);`  在C++中用new运算符  如`p2 = (char *)malloc(10);`  但是注意`p1、p2`本身是在栈中的。  

###### 		2.2  申请后系统的响应  

​			栈：只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出。 

​			堆： 首先应该知道操作系统有一个		记录空闲内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空		闲 结点链表中删除，并将该结点的空间分配给程序，另外，对于大多数系统，会在这块内存空间中的首地址处记录本次分配的大		小，这样，代码中的delete语句才能正确的释放本内存空间。另外，由于找到的堆结点的大小不一定正好等于申请的大小，系统会自		动的将多余的那部分重新放入空闲链表中。 

###### 		2.3申请大小的限制  

​			栈：在Windows下,栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意思是栈顶的地址和栈的最大容量是系统		预先规定好的，在WINDOWS下，栈的大小是2M（也可能是1M，它是一个编译时就确定的常数），如果申请的空间超过栈的剩余空		间时，将提示overflow。因此，能从栈获得的空间较小  。  

​			堆：堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储的空闲内存地址的，自然是不连续的，		而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较		大。  

###### 		2.4申请效率的比较：

​			栈由系统自动分配，速度较快。但程序员是无法控制的。  堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便.  另外，在Windows下，最好的方式是用VirtualAlloc分配内存，它不是在堆，也不是在栈，是直接在进程的地址空间中保留一块内存，虽然用起来最不方便。但是速度快，也最灵活。 

###### 		 2.5堆和栈中的存储内容 ：

​			栈：在函数调用时，第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可执行语句）的地址，然后是函数的各个参数，在大多数的C编译器中，参数是由右往左入栈的，然后是函数中的局部变量。注意静态变量是不入栈的。  当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地址，也就是主函数中的下一条指令，程序由该点继续运行。  

​			堆：一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容有程序员安排。  

###### 		2.6存取效率的比较：

```c
char s1[] = "aaaaaaaaaaaa";  //aaaaaaaaaaa是在运行时刻赋值的；
char *s2 = "bbbbbbbbbbbbbb";  //而bbbbbbbbbbb是在编译时就确定的；
```

​		但是，在以后的存取中，在栈上的数组比指针所指向的字符串(例如堆)快。  

​		比如： 

```c
void main()  {
    char a = 1;  
    char c[] = "1234567890";  
    char *p ="1234567890";  
    a = c[1];  a = p[1];  
    return;  
}
```



```asm
对应的汇编代码 
10: a = c[1];
00401067 8A 4D F1 mov cl,
byte ptr [ebp-0Fh]  
0040106A 88 4D FC mov byte ptr [ebp-4],cl  11: a = p[1];  
0040106D 8B 55 EC mov edx,dword ptr [ebp-14h]  
00401070 8A 42 01 mov al,byte ptr [edx+1]  
00401073 88 45 FC mov byte ptr [ebp-4],
```

​				第一种在读取时直接就把字符串中的元素读到寄存器cl中，而第二种则要先把指针值读到edx寄存器中，在根据 edx寄存器读取		字符，显然慢了。   





#### 阿姆达尔定理

阿姆达尔定理（Amdahl's Law）是计算机科学中的一个重要原理，用于描述在提高系统性能时，限制因素和并行化效果之间的关系。该定理由计算机科学家Gene Amdahl在1967年提出，它对并行计算的设计和性能优化产生了深远的影响。

阿姆达尔定理的核心思想是，在一个计算任务中，如果只有一部分工作可以并行化处理，而其余工作是串行的，那么无论多么强大的计算资源都无法让整个任务的执行时间减小得太多。该定理提供了一个理论上的上限，限制了系统性能的提升。

阿姆达尔定理通常表示为以下公式：
$$
S_{\text{total}} = \frac{1}{{(1 - P) + \frac{P}{N}}}\\

1、表示系统总体加速比（Speedup），即在并行化任务后整体性能提升的倍数。\\
2、P 表示可以并行化处理的部分的比例（通常是0到1之间的小数）。\\
3、N 表示并行处理的处理单元数量，例如CPU核心或线程数。\\
$$



根据阿姆达尔定理，当 \(N\) 变大时，系统的总体加速比 \(S_{\text{total}}\) 会趋向一个有限的上限，这意味着不可能无限制地提高性能。无论如何增加处理单元的数量，最终总体性能的提升将受到串行部分 \(1 - P\) 的限制。

要充分利用并行计算，需要降低串行部分的影响（\(1 - P\)），这可以通过优化算法、数据结构和硬件来实现。阿姆达尔定理的关键教训是，系统性能的提高不仅仅取决于硬件的增强，还依赖于设计和算法的改进，以减少串行部分并提高并行部分的效率。

总的来说，阿姆达尔定理强调了在并行计算中需要综合考虑串行和并行部分，以实现最佳性能提升，而不是简单地增加处理单元的数量。这个原理对于计算机体系结构、并行编程和性能优化非常重要。
